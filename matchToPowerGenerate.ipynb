{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "ea69a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5503d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "forder= os.listdir('1월 데이터')\n",
    "\n",
    "forder.sort()\n",
    "# print(forder)\n",
    "\n",
    "# exit()\n",
    "weather_by_region = {}\n",
    "for file in forder:\n",
    "    csv = pd.read_csv('1월 데이터/' + file, encoding='CP949')\n",
    "    csv = csv.drop(['지점명'], axis=1)\n",
    "    groups = csv.groupby(csv.columns[0])\n",
    "    for i in groups:\n",
    "        if weather_by_region.get(i[0]) is not None:\n",
    "            weather_by_region[i[0]].append(list(i))\n",
    "        else:\n",
    "            weather_by_region[i[0]] = list(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(weather_by_region[310][1])\n",
    "\n",
    "for i in weather_by_region:\n",
    "    region_data=weather_by_region[i]\n",
    "    \n",
    "    concated_data = region_data[1]\n",
    "    size = len(region_data)\n",
    "    for j in range(2,size):\n",
    "        concated_data = pd.concat([concated_data, region_data[j][1]])\n",
    "    \n",
    "    region_data = concated_data.values\n",
    "    size=len(region_data)\n",
    "    # print(region_data[567])\n",
    "    result = []\n",
    "    sum = np.zeros(14).astype(float)\n",
    "    \n",
    "    for j in range(size):\n",
    "        row_data = region_data[j][2:].astype(float)\n",
    "        sum += row_data\n",
    "        if (j+1) % 60 == 0:\n",
    "            result.append(sum/60)\n",
    "            sum = np.zeros(14)\n",
    "\n",
    "    weather_by_region[i]=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f85a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -2.585     ,    0.        ,    0.        ,    0.        ,\n",
       "        275.57833333,    0.        ,    3.45833333,    0.        ,\n",
       "       1027.78833333,    0.        , 1029.58833333,    0.        ,\n",
       "         21.28      ,    0.        ])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_by_region[310][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "powers = []\n",
    "forder = os.listdir('2022_01_energy/2022_01')\n",
    "\n",
    "forder=sorted(forder,key=lambda x:int(x.split('.')[0]))\n",
    "# print(forder)\n",
    "\n",
    "for file in forder:\n",
    "    xlsx = pd.read_excel('2022_01_energy/2022_01/'+file, engine='openpyxl', skiprows=range(4))\n",
    "    xlsx = xlsx.iloc[:-1, :]  #row remove\n",
    "    powers.append(xlsx)\n",
    "    \n",
    "# powers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5343d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 데이터프레임을 하나의 리스트로 합침.\n",
    "all_powers = [power for df in powers for power in df.to_numpy()]\n",
    "\n",
    "combined_powers = pd.DataFrame(all_powers, columns=['Datetime', 'Power'])\n",
    "powers_np = combined_powers.to_numpy()\n",
    "powers_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "50c96e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#삽입할 위치\n",
    "insert_positions = [0]+[i for i in range(23, len(powers_np), 24)]\n",
    "\n",
    "num_inserts = len(insert_positions)\n",
    "\n",
    "# 타임스탬프 하루씩 증가하게 생성\n",
    "timestamps = [pd.Timestamp('2022-01-01 00:00:00') + pd.Timedelta(days=i) for i in range(num_inserts)]\n",
    "\n",
    "# [타임스탬프 , 0.0]\n",
    "insert_values = np.array([[timestamps[i], 0.0] for i in range(num_inserts)], dtype=object)\n",
    "\n",
    "powers_np = np.insert(powers_np, insert_positions, insert_values, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "6bd97b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(743, 2)\n"
     ]
    }
   ],
   "source": [
    "print(powers_np.shape)\n",
    "# for i in weather_by_region:\n",
    "#     print(len(weather_by_region[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "1e5a8e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, weather, energy):\n",
    "        self.weather = weather # 일자별 기상 데이터가 저장된 딕셔너리\n",
    "        self.energy = energy # 에너지 리스트, 일자 상관없음.\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.energy)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        energy = self.energy[idx][1]\n",
    "        weather_data = []\n",
    "        \n",
    "        for region_data in self.weather.values(): # 각 지역별 값.\n",
    "            # print(region_data[idx])\n",
    "            region_weather = region_data[idx]\n",
    "            region_weather = np.nan_to_num(region_weather, nan=0)\n",
    "            weather_data.append(region_weather)\n",
    "        \n",
    "        weather_data = torch.tensor(weather_data)\n",
    "        \n",
    "        return weather_data, energy\n",
    "dataset = CustomDataset(weather_by_region, powers_np)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "148938af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n",
      "data : torch.Size([10, 76, 14]) result : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "for data,result in dataloader:\n",
    "    # print(np.array(data[0]))\n",
    "    print(f'data : {data.shape} result : {result.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "9c8a79d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "class predictModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(predictModel, self).__init__()\n",
    "        self.dense = nn.Linear(76, 1)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # print(\"size of x: \", x) # torch.Size([10, 23, 76, 14])\n",
    "        x = x.permute(0,1,3,2) # x.shape: (10, 23, 14, 76)\n",
    "        x = self.dense(x) # x.shape: (10, 23, 14, 1)\n",
    "        x = x.squeeze(-1) # x.shape: (10, 23, 14)\n",
    "        out, _ = self.rnn(x)  # out shape: (batch_size, seq_len, hidden_size)\n",
    "        out = self.fc(out[:, -1, :])  # out shape: (batch_size, output_size)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "0dd0d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    criterion = nn.MSELoss()\n",
    "    # 옵티마이저 정의\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for data, result in dataloader:\n",
    "        optimizer.zero_grad()  # 경사 초기화\n",
    "        # print(data.shape)\n",
    "\n",
    "        outputs = model(data)  # 순전파\n",
    "        print(f'outputs.shape : {outputs.shape} result.shape : {result.shape}')\n",
    "        loss = criterion(outputs, result)  # 손실 계산\n",
    "        loss.backward()  # 역전파\n",
    "        optimizer.step()  # 파라미터 업데이트\n",
    "        print(f'train loss: {loss.item():.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "7644c306",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "number of dims don't match in permute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49247/687750709.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_49247/3725455761.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# print(data.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 순전파\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'outputs.shape : {outputs.shape} result.shape : {result.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 손실 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_49247/3261296400.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# print(\"size of x: \", x) # torch.Size([10, 23, 76, 14])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x.shape: (10, 23, 14, 76)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x.shape: (10, 23, 14, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x.shape: (10, 23, 14)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: number of dims don't match in permute"
     ]
    }
   ],
   "source": [
    "epoch=100\n",
    "model = predictModel(14, 128,23)\n",
    "\n",
    "for i in range(epoch):\n",
    "    train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94b9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2f5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
